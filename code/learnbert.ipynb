{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0112 10:44:26.544201 14300 file_utils.py:35] PyTorch version 1.1.0 available.\n",
      "G:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "G:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "G:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "G:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "G:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "G:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from IPython . display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch version: 1.1.0\n"
     ]
    }
   ],
   "source": [
    "PRETRAINED_MODEL_NAME = \"bert-base-chinese\"\n",
    "\n",
    "tokenizer = BertTokenizer . from_pretrained( PRETRAINED_MODEL_NAME)\n",
    "\n",
    "clear_output()\n",
    "print(\"Pytorch version:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "字典大小: 21128\n"
     ]
    }
   ],
   "source": [
    "vocab = tokenizer.vocab\n",
    "\n",
    "print(\"字典大小:\",len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token               index          \n",
      "-------------------------\n",
      "fps                 11671\n",
      "##√                 13532\n",
      "##廷                 15512\n",
      "##①                 13556\n",
      "mk                  11629\n",
      "email                8307\n",
      "##牟                 17340\n",
      "作                     868\n",
      "疵                    4560\n",
      "##伪                 13898\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random_tokens = random.sample(list(vocab),10)\n",
    "\n",
    "random_ids = [vocab [t] for t in random_tokens]\n",
    "\n",
    "print(\"{0:20}{1:15}\".format(\"token\",\"index\"))\n",
    "\n",
    "print(\"-\"*25)\n",
    "\n",
    "for t,id in zip(random_tokens, random_ids):\n",
    "    print(\"{0:15}{1:10}\".format(t,id))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ㄅ', 647)\n",
      "('ㄆ', 648)\n",
      "('ㄇ', 649)\n",
      "('ㄉ', 650)\n",
      "('ㄋ', 651)\n",
      "('ㄌ', 652)\n",
      "('ㄍ', 653)\n",
      "('ㄎ', 654)\n",
      "('ㄏ', 655)\n",
      "('ㄒ', 656)\n"
     ]
    }
   ],
   "source": [
    "indices = list(range(647,657))\n",
    "\n",
    "some_pairs = [(t,idx) for t, idx in vocab.items() if idx in indices]\n",
    "\n",
    "for pair in some_pairs:\n",
    "    \n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]等到潮水[MASK]了，就知道谁没穿裤子\n",
      "['[CLS]', '等', '到', '潮', '水', '[MASK]', '了', '，', '就', '知'] ...\n",
      "[101, 5023, 1168, 4060, 3717, 103, 749, 8024, 2218, 4761] ...\n"
     ]
    }
   ],
   "source": [
    "text = \"[CLS]等到潮水[MASK]了，就知道谁没穿裤子\"\n",
    "\n",
    "tokens = tokenizer.tokenize(text)\n",
    "\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(text)\n",
    "\n",
    "print(tokens[:10],'...')\n",
    "\n",
    "print(ids[:10],'...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入的 tokens : ['[CLS]', '等', '到', '潮', '水', '过', '了', '，', '就', '知'] ...\n",
      "--------------------------------------------------\n",
      "Top 1 (78%):['[CLS]', '等', '到', '潮', '水', '来', '了', '，', '就', '知']\n",
      "Top 2 ( 4%):['[CLS]', '等', '到', '潮', '水', '到', '了', '，', '就', '知']\n",
      "Top 3 ( 2%):['[CLS]', '等', '到', '潮', '水', '过', '了', '，', '就', '知']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import BertForMaskedLM\n",
    "# 除了 tokens 以外还要辨别 segment ids\n",
    "tokens_tensor = torch.tensor([ids]) # (1, seq_len)\n",
    "\n",
    "segments_tensors = torch.zeros_like(tokens_tensor) # (1, seq_len)\n",
    "\n",
    "maskedLM_model = BertForMaskedLM.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "\n",
    "clear_output()\n",
    "\n",
    "# 使用 masked LM 估计[MASK] 位置代表的实际 token\n",
    "\n",
    "maskedLM_model.eval()\n",
    "with torch.no_grad():\n",
    "    \n",
    "    outputs = maskedLM_model(tokens_tensor, segments_tensors)\n",
    "    \n",
    "    predictions = outputs[0]\n",
    "    \n",
    "del maskedLM_model\n",
    "\n",
    "# 将 [MASK] 位置的概率分布做 top k 最有可能的 tokens 出来\n",
    "\n",
    "masked_index = 5\n",
    "\n",
    "k = 3\n",
    "\n",
    "\n",
    "probs, indices = torch.topk(torch.softmax(predictions[0, masked_index], -1), k)\n",
    "\n",
    "predicted_tokens = tokenizer.convert_ids_to_tokens(indices.tolist())\n",
    "\n",
    "# 显示 top k 可能的字， 一般取top 1 当预测值\n",
    "\n",
    "print(\"输入的 tokens :\", tokens[:10],'...')\n",
    "\n",
    "print('-'*50)\n",
    "\n",
    "for i, (t, p) in enumerate(zip(predicted_tokens, probs), 1):\n",
    "    \n",
    "    tokens[masked_index] = t\n",
    "    print(\"Top {} ({:2}%):{}\".format(i, int(p.item()*100), tokens[:10], '...'))\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jt -t oceans16 -f fira -fs 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
